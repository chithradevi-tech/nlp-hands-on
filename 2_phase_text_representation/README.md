Text Representation (Vectorization)

Vectorization is the process of converting text data into numeric data so that
future data analysis and machine learning techniques can be applied
â€¢ Most ML techniques require text data to be cleaned, normalized and in a numeric format
â€¢ Some techniques, such as sentiment analysis, require text data to be in its raw text form

Count Vectorization
TF-IDF Vectorization
Embeddings

DF
Clean, normalized text is vectorized as a Document-Term Matrix (DTM)
â€¢ Each row represents a document, and each column represents a term
â€¢ The values within the DTM can be word counts, TF-IDF scores, or other calculated values

A DTM is a bag of words representation of text, where each document is
represented by how often certain words appear, regardless of word order

ğŸ§  What Are Word Embeddings?
Word embeddings are a way to turn words into numbers, so computers can understand them.

But not just any numbers â€” these numbers (called vectors) are smart:

Words with similar meanings get similar numbers.

Words like â€œcatâ€, â€œdogâ€, and â€œpetâ€ will have vectors that are close together.

Words like â€œcarâ€ and â€œappleâ€ will be far apart.

ğŸ§© Why Use Word Embeddings?
Letâ€™s say you want a computer to understand that:

â€œkingâ€ and â€œqueenâ€ are related

â€œkingâ€ and â€œappleâ€ are not

Word embeddings make this possible by putting each word in a map of meaning.

ğŸ§º What is Bag of Words?
Bag of Words is a basic way to turn text into numbers for machine learning.

It:

Ignores grammar and word order

Just counts how many times each word appears in the text

Imagine you put all the words from your sentences into a "bag", mix them up, and count each word. Thatâ€™s why itâ€™s called "Bag of Words".
