{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e92dbeba-2094-410f-b9a8-ecaefd19050f",
   "metadata": {},
   "source": [
    "### The spaCy library can handle many NLP tasks, including tokenization, lemmatization, stop words, and more\n",
    "- The first step is to turn a text string into a spaCy doc object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb98b4f-1af5-4f00-a6d4-6c2d272ff232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              when life gives you lemons make lemonade \n",
       "1                              she bought 2 lemons for 1 at maven market\n",
       "2                         a dozen lemons will make a gallon of lemonade \n",
       "3                                  lemon lemon lemons lemon lemon lemons\n",
       "4    hes running to the market to get a lemon  theres a great sale today\n",
       "5                  does maven market carry eureka lemons or meyer lemons\n",
       "6                       an arnold palmer is half lemonade half iced tea \n",
       "7                                                iced tea is my favorite\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a list of sentences\n",
    "data = [\n",
    "    \"When life gives you lemons, make lemonade! ðŸ™‚\",\n",
    "    \"She bought 2 lemons for $1 at Maven Market.\",\n",
    "    \"A dozen lemons will make a gallon of lemonade. [AllRecipes]\",\n",
    "    \"lemon, lemon, lemons, lemon, lemon, lemons\",\n",
    "    \"He's running to the market to get a lemon â€” there's a great sale today.\",\n",
    "    \"Does Maven Market carry Eureka lemons or Meyer lemons?\",\n",
    "    \"An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]\",\n",
    "    \"iced tea is my favorite\"\n",
    "]\n",
    "\n",
    "# expand the column width to see the full sentences\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# turn it into a dataframe\n",
    "data_df = pd.DataFrame(data, columns=[\"sentence\"])\n",
    "\n",
    "# create a test series of sentences for later on\n",
    "test = [\n",
    "    \"We're going to start this course with traditional NLP applications.\",\n",
    "    \"Then we'll move on to modern NLP theory.\",\n",
    "    \"Finally, we'll wrap things up with modern NLP applications.\"\n",
    "]\n",
    "\n",
    "test_series = pd.Series(test)\n",
    "\n",
    "# make a copy of the data in case we mess up later on\n",
    "df = data_df.copy()\n",
    "\n",
    "# lowercase text\n",
    "df['sentence_clean'] = df['sentence'].str.lower()\n",
    "\n",
    "# remove text between brackets, including the brackets\n",
    "# ChatGPT: use str.replace with regex=true on a series to replace all text within brackets including the brackets, with an empty string\n",
    "df['sentence_clean'] = df['sentence_clean'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "\n",
    "# remove punctuation\n",
    "# ChatGPT: use str.replace with regex=true on a series to replace all punctuation with an empty string\n",
    "df['sentence_clean'] = df['sentence_clean'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "# put all text preprocessing steps into a function to better organize our code\n",
    "def lower_replace(series):\n",
    "    output = series.str.lower()\n",
    "    output = output.str.replace(r'\\[.*?\\]', '', regex=True) # remove words in brackets\n",
    "    output = output.str.replace(r'[^\\w\\s]', '', regex=True) # remove punctuation\n",
    "    return output\n",
    "\n",
    "# try it out on our test series\n",
    "lower_replace(test_series)\n",
    "\n",
    "# use the lower_remove function - the output has lowercased letters, no words in brackets and no punctuation\n",
    "lower_replace(df.sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eb9971-4907-45bf-97ca-1538b578bd8f",
   "metadata": {},
   "source": [
    "### Text Preprocessing with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24086e7b-daea-49c3-954d-aedd0bcceaee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When life gives you lemons, make lemonade! ðŸ™‚</td>\n",
       "      <td>when life gives you lemons make lemonade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She bought 2 lemons for $1 at Maven Market.</td>\n",
       "      <td>she bought 2 lemons for 1 at maven market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A dozen lemons will make a gallon of lemonade. [AllRecipes]</td>\n",
       "      <td>a dozen lemons will make a gallon of lemonade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemon, lemon, lemons, lemon, lemon, lemons</td>\n",
       "      <td>lemon lemon lemons lemon lemon lemons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He's running to the market to get a lemon â€” there's a great sale today.</td>\n",
       "      <td>hes running to the market to get a lemon  theres a great sale today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Does Maven Market carry Eureka lemons or Meyer lemons?</td>\n",
       "      <td>does maven market carry eureka lemons or meyer lemons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]</td>\n",
       "      <td>an arnold palmer is half lemonade half iced tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iced tea is my favorite</td>\n",
       "      <td>iced tea is my favorite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  sentence  \\\n",
       "0                             When life gives you lemons, make lemonade! ðŸ™‚   \n",
       "1                              She bought 2 lemons for $1 at Maven Market.   \n",
       "2              A dozen lemons will make a gallon of lemonade. [AllRecipes]   \n",
       "3                               lemon, lemon, lemons, lemon, lemon, lemons   \n",
       "4  He's running to the market to get a lemon â€” there's a great sale today.   \n",
       "5                   Does Maven Market carry Eureka lemons or Meyer lemons?   \n",
       "6            An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]   \n",
       "7                                                  iced tea is my favorite   \n",
       "\n",
       "                                                        sentence_clean  \n",
       "0                            when life gives you lemons make lemonade   \n",
       "1                            she bought 2 lemons for 1 at maven market  \n",
       "2                       a dozen lemons will make a gallon of lemonade   \n",
       "3                                lemon lemon lemons lemon lemon lemons  \n",
       "4  hes running to the market to get a lemon  theres a great sale today  \n",
       "5                does maven market carry eureka lemons or meyer lemons  \n",
       "6                     an arnold palmer is half lemonade half iced tea   \n",
       "7                                              iced tea is my favorite  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view our dataframe once again\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8b5e15e-46fb-4840-8e59-71ab5c021dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7504e830-4d62-4de6-879f-805ffeadf6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the spacy english model\n",
    "# run this code in the command line if you get an error: python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9bd70b1-5634-4ecf-b19f-b9ac26161082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when life gives you lemons make lemonade '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at just one phrase\n",
    "phrase = df.sentence_clean[0]\n",
    "phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcc87f6b-d7cd-4976-87e2-8a4488d6a9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "when life gives you lemons make lemonade "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn the phrase into a spacy document\n",
    "doc = nlp(phrase)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143193fd-d276-4efa-be25-d9e8a7b715b3",
   "metadata": {},
   "source": [
    "### Tokenization lets you break text up into smaller units, like words\n",
    "- Text strings are often split by whitespace to make tokens\n",
    "- Sentence tokenization, word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dbb8c0f-bf3b-47d5-82e4-d5c48b5e92a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when', 'life', 'gives', 'you', 'lemons', 'make', 'lemonade']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# break up the text into tokens\n",
    "[token.text for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0bf6de-91bf-4ae6-b415-40924d7aaa9a",
   "metadata": {},
   "source": [
    "### Tokenization using nltk toolkit - install nltk\n",
    "- !pip install nltk\n",
    "- import nltk\n",
    "  nltk.download('popular')\n",
    "  nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e32448fd-91d3-4a68-8180-c46eb717818b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK installed successfully!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(\"NLTK installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06e550bf-6ba3-46f9-852b-939ef434dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "#nltk.download('punkt')\n",
    "# Sample text for tokenization\n",
    "txt = \"NLTK provides powerful tools for tokenization. It includes word tokenization and sentence tokenization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4df93e37-0b31-400a-9e0b-67b13653e0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLTK', 'provides', 'powerful', 'tools', 'for', 'tokenization', '.', 'It', 'includes', 'word', 'tokenization', 'and', 'sentence', 'tokenization']\n"
     ]
    }
   ],
   "source": [
    "# Word tokenization\n",
    "words = word_tokenize(txt)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1ee9b60-f6cd-4fdf-a609-c7db0edaea10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLTK provides powerful tools for tokenization.', 'It includes word tokenization and sentence tokenization']\n"
     ]
    }
   ],
   "source": [
    "# Word tokenization\n",
    "sent = sent_tokenize(txt)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fe63d41-21e5-4dd1-a001-3e71c8d1d7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'how', 'are', '$', 'you', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "input_str = \"hello how are$ you!!\"\n",
    "tokens = word_tokenize(input_str)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "049bea7c-6039-4932-a75b-0e5400a97ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello how are you\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "#nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "\n",
    "input_str = \"hello how are$ you!!\"\n",
    "\n",
    "# Tokenize\n",
    "tokens = nltk.word_tokenize(input_str)\n",
    "\n",
    "# Remove the special characters\n",
    "clean_tokens = [token for token in tokens if token.isalnum()]\n",
    "\n",
    "clean_str = ' '.join(clean_tokens)\n",
    "\n",
    "print(clean_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb12c352-f570-4833-948c-76c9b6535a46",
   "metadata": {},
   "source": [
    "### Lemmatization reduces words to their base form\n",
    "- spaCy uses a combination of linguistic rules and statistical models to lemmatize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3208423-ff16-4d8d-80f2-7c24226661fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when', 'life', 'give', 'you', 'lemon', 'make', 'lemonade']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in addition, lemmatize the tokens to their root form\n",
    "[token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9994cf-920d-421f-a71a-3653dfa366a7",
   "metadata": {},
   "source": [
    "### Stop words are words without any significant meaning\n",
    "- You can view the full stop word list in spaCy with the code print(nlp.Defaults.stop_words)\n",
    "\n",
    "### Stop words are words that are filtered out before or after processing natural language data because they are deemed to have little semantic value or are otherwise insignificant for the task at hand. \n",
    "\n",
    "Why Remove Stop Words?\n",
    "- Noise Reduction: Removing stop words helps reduce the amount of irrelevant data, allowing models to focus on more meaningful words. \n",
    "innovationyourself.com\n",
    "\n",
    "- Improved Computational Efficiency: Eliminating stop words reduces the size of the dataset, leading to faster processing and lower computational costs.\n",
    "\n",
    "- Enhanced Model Performance: By focusing on content-rich words, models can achieve better accuracy in tasks like text classification and sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f32b69a4-dce9-4b80-a2f2-2d7b8428bba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['life', 'give', 'lemon', 'lemonade']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in addition, remove the stop words\n",
    "norm = [token.lemma_ for token in doc if not token.is_stop]\n",
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92a3d82e-49d0-4cae-b71d-81efffd20068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anything',\n",
       " 'somewhere',\n",
       " 'hence',\n",
       " 'became',\n",
       " 'front',\n",
       " 'toward',\n",
       " 'but',\n",
       " 'thru',\n",
       " 'along',\n",
       " 'amongst']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# side note: view the spacy stop word list\n",
    "list(nlp.Defaults.stop_words)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7df93388-475c-4a04-a545-37fc709cbde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'life give lemon lemonade'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the list into a string for easier analysis later on\n",
    "' '.join(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57710065-d0e0-4fb0-a1c0-77c70a42b5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample sentence, showing off the stop words filtration\n",
      "['sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample Sentence\n",
    "sentence = \"This is a sample sentence, showing off the stop words filtration\"\n",
    "# Tokenize the Sentence\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "# Filter out stopwords\n",
    "new_sentence = [word for word in words if word.lower() not in stopwords.words('english')]\n",
    "# Print the final sentence\n",
    "print(sentence)\n",
    "print(new_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e35db85-f0f7-4d43-a2d9-c709ff999c3b",
   "metadata": {},
   "source": [
    "### Create a token_lemma_nonstop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7336eb6-7c9f-4c4c-8941-e9ab3b92ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all text preprocessing steps into a function to better organize our code\n",
    "def token_lemma_nonstop(text):\n",
    "    doc = nlp(text)\n",
    "    output = [token.lemma_ for token in doc if not token.is_stop] # tokenize, lemmatize and remove stop words\n",
    "    output = ' '.join(output) # convert list into string\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6afaa2a1-14a6-46f0-bbdd-61cd1b5d9a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go start course traditional NLP application .\n",
       "1                              modern NLP theory .\n",
       "2    finally , wrap thing modern NLP application .\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it out on our test series, this time using .apply\n",
    "test_series.apply(token_lemma_nonstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23bdffc7-1ff0-4d71-84e1-f5bd1f723410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       life give lemon lemonade\n",
       "1                     buy 2 lemon 1 maven market\n",
       "2                    dozen lemon gallon lemonade\n",
       "3            lemon lemon lemon lemon lemon lemon\n",
       "4        s run market lemon   s great sale today\n",
       "5    maven market carry eureka lemon meyer lemon\n",
       "6       arnold palmer half lemonade half ice tea\n",
       "7                               ice tea favorite\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the function on a column of text - the output is tokenized, lemmatized and has no stop words\n",
    "lower_replace(df.sentence).apply(token_lemma_nonstop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc3e121-a927-4295-87ee-b29c0de432e3",
   "metadata": {},
   "source": [
    "### Parts of speech (POS) tagging lets you label nouns, verbs, etc. within text data\n",
    "- This is optional, but is sometimes used as a filtering technique to only look at nouns and pronouns for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e497b7e2-9d04-4c3b-a52c-24fc9a78e88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'life give lemon lemonade'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at just one phrase\n",
    "phrase2 = lower_replace(df.sentence).apply(token_lemma_nonstop)[0]\n",
    "phrase2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "faab1116-710c-4897-bdac-42222ba12354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "life give lemon lemonade"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn the phrase into a spacy document\n",
    "doc2 = nlp(phrase2)\n",
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23b1c985-f40b-4e6b-b673-6b7b899f2147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('life', 'NOUN'), ('give', 'VERB'), ('lemon', 'NOUN'), ('lemonade', 'PROPN')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the parts of speech tags\n",
    "pos = [(token.text, token.pos_) for token in doc2]\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a762e9af-05b7-40e6-951c-8fdc74567804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['life', 'lemon', 'lemonade']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter on just the nouns and proper nouns\n",
    "nouns = [(token.text) for token in doc2 if token.pos_ in ['NOUN', 'PROPN']]\n",
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99ea1aef-671b-4c1c-a157-ceee5acd330b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'life lemon lemonade'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the list into a string for easier analysis later on\n",
    "' '.join(nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b5d503-f27f-45ff-bb89-459241c197c7",
   "metadata": {},
   "source": [
    "### Create a filter_pos function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66e2d2ea-6dc9-432c-b232-fb857818179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by parts of speech\n",
    "def filter_pos(text, pos_list=['NOUN', 'PROPN']):\n",
    "    doc = nlp(text)\n",
    "    output = [(token.text) for token in doc if token.pos_ in pos_list] # return on the nouns and pronouns\n",
    "    output = ' '.join(output) # convert list into string\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1154ac98-6fd0-447b-88d0-045777896700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    course NLP applications\n",
       "1                 NLP theory\n",
       "2    things NLP applications\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it out on our test data\n",
    "test_series.apply(filter_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8fd58a3-3ecc-45b3-8504-48d305d4de35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    life lemon lemonade\n",
       "1                     lemon maven market\n",
       "2            dozen lemon gallon lemonade\n",
       "3    lemon lemon lemon lemon lemon lemon\n",
       "4              s market lemon sale today\n",
       "5        maven market eureka lemon lemon\n",
       "6           palmer lemonade half ice tea\n",
       "7                       ice tea favorite\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the function on a column of text - the output only includes nouns and proper nouns\n",
    "lower_replace(df.sentence).apply(token_lemma_nonstop).apply(filter_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19ef498a-fb45-4c15-9640-46047e3a030d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              life lemon lemonade\n",
       "1               lemon maven market\n",
       "2      dozen lemon gallon lemonade\n",
       "3    lemon lemon lemon lemon lemon\n",
       "4          market lemon sale today\n",
       "5        market eureka lemon lemon\n",
       "6              palmer lemonade tea\n",
       "7                              tea\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice that by switching the order of the normalization steps, we get different results\n",
    "lower_replace(df.sentence).apply(filter_pos).apply(token_lemma_nonstop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c32985-e396-4a97-9efc-ca3b6299355a",
   "metadata": {},
   "source": [
    "## Create an NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c30fbec2-0a18-4d4f-85d2-b9cc677f27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy down the helper functions\n",
    "def lower_replace(series):\n",
    "    output = series.str.lower()\n",
    "    output = output.str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "    output = output.str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "    return output\n",
    "\n",
    "def token_lemma_nonstop(text):\n",
    "    doc = nlp(text)\n",
    "    output = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    output = ' '.join(output)\n",
    "    return output \n",
    "\n",
    "def filter_pos(text, pos_list=['NOUN', 'PROPN']):\n",
    "    doc = nlp(text)\n",
    "    output = [(token.text) for token in doc if token.pos_ in pos_list]\n",
    "    output = ' '.join(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1637c1ff-1436-4e7c-bae2-eda8d710c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an nlp pipeline\n",
    "def nlp_pipeline(series):\n",
    "    output = lower_replace(series)\n",
    "    output = output.apply(token_lemma_nonstop)\n",
    "    output = output.apply(filter_pos)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a5f273f-16e3-4d80-8275-54149d58cad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          nlp application\n",
       "1               nlp theory\n",
       "2    thing nlp application\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the cleaned, normalized and filtered test sentences\n",
    "nlp_pipeline(test_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67c7b23b-1876-4ccc-bb50-a6820632525f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               When life gives you lemons, make lemonade! ðŸ™‚\n",
       "1                                She bought 2 lemons for $1 at Maven Market.\n",
       "2                A dozen lemons will make a gallon of lemonade. [AllRecipes]\n",
       "3                                 lemon, lemon, lemons, lemon, lemon, lemons\n",
       "4    He's running to the market to get a lemon â€” there's a great sale today.\n",
       "5                     Does Maven Market carry Eureka lemons or Meyer lemons?\n",
       "6              An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]\n",
       "7                                                    iced tea is my favorite\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the original sentences\n",
    "df.sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "854d7ec3-a771-4577-8ace-dcb9f0d548cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    life lemon lemonade\n",
       "1                     lemon maven market\n",
       "2            dozen lemon gallon lemonade\n",
       "3    lemon lemon lemon lemon lemon lemon\n",
       "4              s market lemon sale today\n",
       "5        maven market eureka lemon lemon\n",
       "6           palmer lemonade half ice tea\n",
       "7                       ice tea favorite\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the cleaned and normalized sentences\n",
    "text_clean = nlp_pipeline(df.sentence)\n",
    "text_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b60064d-8030-49a6-8330-f578d6599387",
   "metadata": {},
   "source": [
    "### Save your cleaned data as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a28610b0-94a9-4d7c-837c-e5cd91f60481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output as a pickle file to load into a notebook later on\n",
    "pd.to_pickle(text_clean, '../data/text_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d438e-bbd2-4fee-892b-0eb5ac28481f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
